/home/konstantin.smirnov/miniconda3/envs/project_env/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type             | Params | Mode
--------------------------------------------------------
0 | embedding  | Embedding        | 32     | train
1 | lstm1      | LSTM             | 70.7 K | train
2 | activation | ReLU             | 0      | train
3 | lstm2      | LSTM             | 132 K  | train
4 | lstm3      | LSTM             | 132 K  | train
5 | lstm4      | LSTM             | 132 K  | train
6 | fc         | Linear           | 516    | train
7 | loss_fn    | CrossEntropyLoss | 0      | train
--------------------------------------------------------
467 K     Trainable params
0         Non-trainable params
467 K     Total params
1.870     Total estimated model params size (MB)
8         Modules in train mode
0         Modules in eval mode
Epoch 19: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:29<00:00, 41.88it/s, v_num=4vyi]
/home/konstantin.smirnov/miniconda3/envs/project_env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
/home/konstantin.smirnov/miniconda3/envs/project_env/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
                                                                                                                                                        
/home/konstantin.smirnov/miniconda3/envs/project_env/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
Epoch 0, global step 1250: 'val_loss' reached 0.64338 (best 0.64338), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.64.ckpt' as top 1
Epoch 1, global step 2500: 'val_loss' reached 0.63470 (best 0.63470), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.63.ckpt' as top 1
Epoch 2, global step 3750: 'val_loss' reached 0.62578 (best 0.62578), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.63.ckpt' as top 1
Epoch 3, global step 5000: 'val_loss' reached 0.61521 (best 0.61521), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.62.ckpt' as top 1
Epoch 4, global step 6250: 'val_loss' reached 0.59961 (best 0.59961), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.60.ckpt' as top 1
Epoch 5, global step 7500: 'val_loss' reached 0.58047 (best 0.58047), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.58.ckpt' as top 1
Epoch 6, global step 8750: 'val_loss' reached 0.55894 (best 0.55894), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.56.ckpt' as top 1
Epoch 7, global step 10000: 'val_loss' reached 0.53495 (best 0.53495), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.53.ckpt' as top 1
Epoch 8, global step 11250: 'val_loss' was not in top 1
Epoch 9, global step 12500: 'val_loss' reached 0.51540 (best 0.51540), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.52.ckpt' as top 1
Epoch 10, global step 13750: 'val_loss' reached 0.49635 (best 0.49635), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.50.ckpt' as top 1
Epoch 11, global step 15000: 'val_loss' reached 0.47892 (best 0.47892), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.48.ckpt' as top 1
Epoch 12, global step 16250: 'val_loss' reached 0.46391 (best 0.46391), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.46.ckpt' as top 1
Epoch 13, global step 17500: 'val_loss' reached 0.46071 (best 0.46071), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.46.ckpt' as top 1
Epoch 14, global step 18750: 'val_loss' reached 0.44265 (best 0.44265), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.44.ckpt' as top 1
Epoch 15, global step 20000: 'val_loss' reached 0.43907 (best 0.43907), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.44.ckpt' as top 1
Epoch 16, global step 21250: 'val_loss' reached 0.42767 (best 0.42767), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.43.ckpt' as top 1
Epoch 17, global step 22500: 'val_loss' was not in top 1
Epoch 18, global step 23750: 'val_loss' reached 0.41210 (best 0.41210), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len400-best-checkpoint-val_loss=0.41.ckpt' as top 1
Epoch 19, global step 25000: 'val_loss' was not in top 1
`Trainer.fit` stopped: `max_epochs=20` reached.
