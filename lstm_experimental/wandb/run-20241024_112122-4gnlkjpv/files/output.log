/home/konstantin.smirnov/miniconda3/envs/project_env/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type             | Params | Mode
--------------------------------------------------------
0 | embedding  | Embedding        | 32     | train
1 | lstm1      | LSTM             | 70.7 K | train
2 | activation | ReLU             | 0      | train
3 | lstm2      | LSTM             | 132 K  | train
4 | lstm3      | LSTM             | 132 K  | train
5 | lstm4      | LSTM             | 132 K  | train
6 | fc         | Linear           | 516    | train
7 | loss_fn    | CrossEntropyLoss | 0      | train
--------------------------------------------------------
467 K     Trainable params
0         Non-trainable params
467 K     Total params
1.870     Total estimated model params size (MB)
8         Modules in train mode
0         Modules in eval mode
Epoch 27: 100%|███████████████████████████████████████████████████████████████████████████████████| 200/200 [00:01<00:00, 105.25it/s, v_num=kjpv]
/home/konstantin.smirnov/miniconda3/envs/project_env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
/home/konstantin.smirnov/miniconda3/envs/project_env/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
/home/konstantin.smirnov/miniconda3/envs/project_env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
                                                                                                                                                 
Epoch 0, global step 200: 'val_loss' reached 0.69376 (best 0.69376), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.69.ckpt' as top 1
Epoch 1, global step 400: 'val_loss' reached 0.66985 (best 0.66985), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.67.ckpt' as top 1
Epoch 2, global step 600: 'val_loss' reached 0.66472 (best 0.66472), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.66.ckpt' as top 1
Epoch 3, global step 800: 'val_loss' reached 0.64496 (best 0.64496), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.64.ckpt' as top 1
Epoch 4, global step 1000: 'val_loss' reached 0.60944 (best 0.60944), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.61.ckpt' as top 1
Epoch 5, global step 1200: 'val_loss' reached 0.48080 (best 0.48080), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.48.ckpt' as top 1
Epoch 6, global step 1400: 'val_loss' was not in top 1
Epoch 7, global step 1600: 'val_loss' reached 0.38487 (best 0.38487), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.38.ckpt' as top 1
Epoch 8, global step 1800: 'val_loss' was not in top 1
Epoch 9, global step 2000: 'val_loss' was not in top 1
Epoch 10, global step 2200: 'val_loss' reached 0.28655 (best 0.28655), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.29.ckpt' as top 1
Epoch 11, global step 2400: 'val_loss' reached 0.23586 (best 0.23586), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.24.ckpt' as top 1
Epoch 12, global step 2600: 'val_loss' was not in top 1
Epoch 13, global step 2800: 'val_loss' was not in top 1
Epoch 14, global step 3000: 'val_loss' was not in top 1
Epoch 15, global step 3200: 'val_loss' reached 0.18838 (best 0.18838), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.19.ckpt' as top 1
Epoch 16, global step 3400: 'val_loss' reached 0.13058 (best 0.13058), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.13.ckpt' as top 1
Epoch 17, global step 3600: 'val_loss' was not in top 1
Epoch 18, global step 3800: 'val_loss' was not in top 1
Epoch 19, global step 4000: 'val_loss' reached 0.10665 (best 0.10665), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.11.ckpt' as top 1
Epoch 20, global step 4200: 'val_loss' reached 0.08026 (best 0.08026), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.08-v1.ckpt' as top 1
Epoch 21, global step 4400: 'val_loss' was not in top 1
Epoch 22, global step 4600: 'val_loss' was not in top 1
Epoch 23, global step 4800: 'val_loss' reached 0.06736 (best 0.06736), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.07.ckpt' as top 1
Epoch 24, global step 5000: 'val_loss' was not in top 1
Epoch 25, global step 5200: 'val_loss' was not in top 1
Epoch 26, global step 5400: 'val_loss' was not in top 1
Epoch 27, global step 5600: 'val_loss' was not in top 1
Epoch 28, global step 5800: 'val_loss' reached 0.06228 (best 0.06228), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.06.ckpt' as top 1
Epoch 29, global step 6000: 'val_loss' was not in top 1
Epoch 30, global step 6200: 'val_loss' reached 0.04185 (best 0.04185), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.04.ckpt' as top 1
Epoch 31, global step 6400: 'val_loss' reached 0.03541 (best 0.03541), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.04.ckpt' as top 1
Epoch 32, global step 6600: 'val_loss' was not in top 1
Epoch 33, global step 6800: 'val_loss' reached 0.01761 (best 0.01761), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.02.ckpt' as top 1
Epoch 34, global step 7000: 'val_loss' was not in top 1
Epoch 35, global step 7200: 'val_loss' was not in top 1
Epoch 36, global step 7400: 'val_loss' was not in top 1
Epoch 37, global step 7600: 'val_loss' was not in top 1
Epoch 38, global step 7800: 'val_loss' was not in top 1
Epoch 39, global step 8000: 'val_loss' was not in top 1
Epoch 40, global step 8200: 'val_loss' was not in top 1
Epoch 41, global step 8400: 'val_loss' was not in top 1
Epoch 42, global step 8600: 'val_loss' was not in top 1
Epoch 43, global step 8800: 'val_loss' reached 0.01269 (best 0.01269), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.01.ckpt' as top 1
Epoch 44, global step 9000: 'val_loss' was not in top 1
Epoch 45, global step 9200: 'val_loss' was not in top 1
Epoch 46, global step 9400: 'val_loss' was not in top 1
Epoch 47, global step 9600: 'val_loss' was not in top 1
Epoch 48, global step 9800: 'val_loss' was not in top 1
Epoch 49, global step 10000: 'val_loss' was not in top 1
Epoch 50, global step 10200: 'val_loss' reached 0.00890 (best 0.00890), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.01.ckpt' as top 1
Epoch 51, global step 10400: 'val_loss' was not in top 1
Epoch 52, global step 10600: 'val_loss' was not in top 1
Epoch 53, global step 10800: 'val_loss' was not in top 1
Epoch 54, global step 11000: 'val_loss' reached 0.00777 (best 0.00777), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.01.ckpt' as top 1
Epoch 55, global step 11200: 'val_loss' was not in top 1
Epoch 56, global step 11400: 'val_loss' reached 0.00410 (best 0.00410), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.00.ckpt' as top 1
Epoch 57, global step 11600: 'val_loss' was not in top 1
Epoch 58, global step 11800: 'val_loss' was not in top 1
Epoch 59, global step 12000: 'val_loss' was not in top 1
Epoch 60, global step 12200: 'val_loss' was not in top 1
Epoch 61, global step 12400: 'val_loss' was not in top 1
Epoch 62, global step 12600: 'val_loss' was not in top 1
Epoch 63, global step 12800: 'val_loss' was not in top 1
Epoch 64, global step 13000: 'val_loss' was not in top 1
Epoch 65, global step 13200: 'val_loss' was not in top 1
Epoch 66, global step 13400: 'val_loss' was not in top 1
Epoch 67, global step 13600: 'val_loss' was not in top 1
Epoch 68, global step 13800: 'val_loss' was not in top 1
Epoch 69, global step 14000: 'val_loss' was not in top 1
Epoch 70, global step 14200: 'val_loss' was not in top 1
Epoch 71, global step 14400: 'val_loss' reached 0.00370 (best 0.00370), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.00.ckpt' as top 1
Epoch 72, global step 14600: 'val_loss' reached 0.00353 (best 0.00353), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.00.ckpt' as top 1
Epoch 73, global step 14800: 'val_loss' reached 0.00329 (best 0.00329), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.00.ckpt' as top 1
Epoch 74, global step 15000: 'val_loss' was not in top 1
Epoch 75, global step 15200: 'val_loss' reached 0.00094 (best 0.00094), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.00.ckpt' as top 1
Epoch 76, global step 15400: 'val_loss' was not in top 1
Epoch 77, global step 15600: 'val_loss' was not in top 1
Epoch 78, global step 15800: 'val_loss' was not in top 1
Epoch 79, global step 16000: 'val_loss' was not in top 1
Epoch 80, global step 16200: 'val_loss' was not in top 1
Epoch 81, global step 16400: 'val_loss' was not in top 1
Epoch 82, global step 16600: 'val_loss' was not in top 1
Epoch 83, global step 16800: 'val_loss' was not in top 1
Epoch 84, global step 17000: 'val_loss' was not in top 1
Epoch 85, global step 17200: 'val_loss' was not in top 1
Epoch 86, global step 17400: 'val_loss' was not in top 1
Epoch 87, global step 17600: 'val_loss' was not in top 1
Epoch 88, global step 17800: 'val_loss' was not in top 1
Epoch 89, global step 18000: 'val_loss' was not in top 1
Epoch 90, global step 18200: 'val_loss' was not in top 1
Epoch 91, global step 18400: 'val_loss' was not in top 1
Epoch 92, global step 18600: 'val_loss' reached 0.00009 (best 0.00009), saving model to '/home/konstantin.smirnov/associative-recurrent-memory-transformer/lstm_experimental/checkpoints/binary_copy/len40-best-checkpoint-val_loss=0.00.ckpt' as top 1
Epoch 93, global step 18800: 'val_loss' was not in top 1
Epoch 94, global step 19000: 'val_loss' was not in top 1
Epoch 95, global step 19200: 'val_loss' was not in top 1
Epoch 96, global step 19400: 'val_loss' was not in top 1
Epoch 97, global step 19600: 'val_loss' was not in top 1
Epoch 98, global step 19800: 'val_loss' was not in top 1
Epoch 99, global step 20000: 'val_loss' was not in top 1
`Trainer.fit` stopped: `max_epochs=100` reached.
